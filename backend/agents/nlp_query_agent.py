"""
NLP Query Agent for MSP Intelligence Mesh Network
Provides natural language interface for insights and data querying
"""
import asyncio
import json
import random
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
import structlog
from transformers import AutoTokenizer, AutoModelForQuestionAnswering, AutoModelForSequenceClassification
import torch
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

from .base_agent import BaseAgent, AgentResponse, AgentMetrics


logger = structlog.get_logger()


class NLPQueryAgent(BaseAgent):
    """NLP Query Agent for natural language interface"""
    
    def __init__(self):
        super().__init__()
        self.agent_id = "nlp_query_agent"
        self.agent_type = "nlp_query"
        self.model_loaded = False
        self.qa_model = None
        self.qa_tokenizer = None
        self.classifier_model = None
        self.classifier_tokenizer = None
        self.vectorizer = None
        self.knowledge_base = {}
        self.query_history = []
        
        self.logger = logger.bind(agent=self.agent_id)
        self.logger.info("NLP Query Agent initialized")
    
    async def initialize(self):
        """Initialize the agent and load models"""
        try:
            self.logger.info("Initializing NLP Query Agent")
            
            # Load question answering model
            try:
                self.qa_tokenizer = AutoTokenizer.from_pretrained("distilbert-base-cased-distilled-squad")
                self.qa_model = AutoModelForQuestionAnswering.from_pretrained("distilbert-base-cased-distilled-squad")
                self.logger.info("QA model loaded successfully")
            except Exception as e:
                self.logger.warning("Could not load QA model, using fallback", error=str(e))
                self.qa_model = None
            
            # Load classification model for intent detection
            try:
                self.classifier_tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased")
                self.classifier_model = AutoModelForSequenceClassification.from_pretrained("distilbert-base-uncased")
                self.logger.info("Classification model loaded successfully")
            except Exception as e:
                self.logger.warning("Could not load classification model, using fallback", error=str(e))
                self.classifier_model = None
            
            # Initialize TF-IDF vectorizer for similarity search
            self.vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')
            
            # Load knowledge base
            await self._load_knowledge_base()
            
            self.model_loaded = True
            self.logger.info("NLP Query Agent initialized successfully")
            
        except Exception as e:
            self.logger.error("Failed to initialize NLP Query Agent", error=str(e))
            raise
    
    async def _load_knowledge_base(self):
        """Load knowledge base for query answering"""
        # Generate synthetic knowledge base
        self.knowledge_base = {
            "system_info": {
                "description": "MSP Intelligence Mesh Network is a collective intelligence platform for Managed Service Providers",
                "features": [
                    "Real-time threat detection and response",
                    "AI-powered collaboration matching",
                    "Federated learning with privacy guarantees",
                    "Predictive analytics and client health monitoring",
                    "Revenue optimization and market intelligence"
                ],
                "agents": [
                    "Threat Intelligence Agent",
                    "Collaboration Matching Agent", 
                    "Federated Learning Agent",
                    "Market Intelligence Agent",
                    "Client Health Agent",
                    "Revenue Optimization Agent",
                    "Anomaly Detection Agent",
                    "NLP Query Agent"
                ]
            },
            "threat_intelligence": {
                "description": "Threat Intelligence Agent provides real-time threat detection and analysis",
                "capabilities": [
                    "CVE analysis and vulnerability assessment",
                    "Threat pattern recognition",
                    "Network security monitoring",
                    "Incident response recommendations"
                ],
                "metrics": {
                    "detection_accuracy": "94.2%",
                    "response_time": "<100ms",
                    "threats_blocked": "2,847 in last 30 days"
                }
            },
            "collaboration": {
                "description": "Collaboration Matching Agent helps MSPs find partnership opportunities",
                "capabilities": [
                    "Skill-based partner matching",
                    "Joint proposal generation",
                    "Revenue sharing calculations",
                    "Success probability assessment"
                ],
                "metrics": {
                    "success_rate": "78%",
                    "opportunities_matched": "156 in last month",
                    "revenue_generated": "$890K through collaborations"
                }
            },
            "federated_learning": {
                "description": "Federated Learning Agent enables privacy-preserving model training",
                "capabilities": [
                    "Distributed model training",
                    "Differential privacy implementation",
                    "Secure aggregation protocols",
                    "Model performance tracking"
                ],
                "metrics": {
                    "privacy_guarantee": "Îµ=0.1",
                    "model_accuracy": "94%",
                    "participating_msps": "1,247"
                }
            },
            "market_intelligence": {
                "description": "Market Intelligence Agent provides pricing and competitive analysis",
                "capabilities": [
                    "Pricing trend analysis",
                    "Competitive intelligence",
                    "Market opportunity identification",
                    "Sentiment analysis"
                ],
                "metrics": {
                    "market_coverage": "15 industries",
                    "pricing_accuracy": "92%",
                    "opportunities_identified": "45 this quarter"
                }
            },
            "client_health": {
                "description": "Client Health Agent monitors client satisfaction and churn risk",
                "capabilities": [
                    "Churn prediction",
                    "Health scoring",
                    "Intervention recommendations",
                    "Satisfaction analysis"
                ],
                "metrics": {
                    "churn_accuracy": "94%",
                    "health_score_avg": "0.87",
                    "interventions_successful": "85%"
                }
            },
            "revenue_optimization": {
                "description": "Revenue Optimization Agent provides forecasting and opportunity detection",
                "capabilities": [
                    "Revenue forecasting",
                    "Upsell prediction",
                    "Pricing optimization",
                    "Market trend analysis"
                ],
                "metrics": {
                    "forecast_accuracy": "92%",
                    "revenue_increase": "35-40% per MSP",
                    "upsell_success": "67%"
                }
            },
            "anomaly_detection": {
                "description": "Anomaly Detection Agent identifies unusual patterns in system operations",
                "capabilities": [
                    "Performance anomaly detection",
                    "Security threat identification",
                    "System health monitoring",
                    "Predictive anomaly forecasting"
                ],
                "metrics": {
                    "detection_accuracy": "96%",
                    "false_positive_rate": "2.3%",
                    "anomalies_detected": "1,247 this month"
                }
            }
        }
        
        self.logger.info("Knowledge base loaded successfully")
    
    async def process_request(self, request: Dict[str, Any]) -> AgentResponse:
        """Process NLP query requests"""
        try:
            request_type = request.get("type", "")
            request_data = request.get("data", {})
            
            start_time = datetime.utcnow()
            
            if request_type == "process_query":
                result = await self._process_query(request_data)
            elif request_type == "classify_intent":
                result = await self._classify_intent(request_data)
            elif request_type == "answer_question":
                result = await self._answer_question(request_data)
            elif request_type == "generate_insights":
                result = await self._generate_insights(request_data)
            elif request_type == "search_knowledge":
                result = await self._search_knowledge(request_data)
            elif request_type == "conversational_interface":
                result = await self._conversational_interface(request_data)
            else:
                result = {"error": f"Unknown request type: {request_type}"}
            
            processing_time = (datetime.utcnow() - start_time).total_seconds() * 1000
            
            return AgentResponse(
                success=True,
                data=result,
                processing_time_ms=processing_time,
                agent_id=self.agent_id,
                timestamp=datetime.utcnow().isoformat()
            )
            
        except Exception as e:
            self.logger.error("Error processing NLP query request", error=str(e))
            return AgentResponse(
                success=False,
                error=str(e),
                agent_id=self.agent_id,
                timestamp=datetime.utcnow().isoformat()
            )
    
    async def _process_query(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Process natural language query"""
        query = data.get("query", "")
        context = data.get("context", {})
        
        if not query:
            return {"error": "No query provided"}
        
        # Store query in history
        self.query_history.append({
            "query": query,
            "timestamp": datetime.utcnow().isoformat(),
            "context": context
        })
        
        # Classify intent
        intent = await self._classify_intent({"query": query})
        
        # Process based on intent
        if intent["intent"] == "question":
            result = await self._answer_question({"query": query, "context": context})
        elif intent["intent"] == "insight_request":
            result = await self._generate_insights({"query": query, "context": context})
        elif intent["intent"] == "knowledge_search":
            result = await self._search_knowledge({"query": query})
        else:
            result = await self._conversational_interface({"query": query, "context": context})
        
        return {
            "query": query,
            "intent": intent,
            "response": result,
            "confidence": intent.get("confidence", 0.8),
            "processing_timestamp": datetime.utcnow().isoformat()
        }
    
    async def _classify_intent(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Classify the intent of a natural language query"""
        query = data.get("query", "").lower()
        
        # Simple rule-based intent classification
        intent_patterns = {
            "question": [
                "what", "how", "why", "when", "where", "who", "which",
                "explain", "describe", "tell me about", "what is", "how does"
            ],
            "insight_request": [
                "show me", "analyze", "insights", "trends", "patterns",
                "dashboard", "report", "summary", "overview", "status"
            ],
            "knowledge_search": [
                "search", "find", "look for", "information about",
                "details on", "more about", "help with"
            ],
            "action_request": [
                "run", "execute", "start", "stop", "generate", "create",
                "update", "refresh", "reload", "trigger"
            ],
            "conversational": [
                "hello", "hi", "thanks", "thank you", "good", "bad",
                "help", "assist", "support"
            ]
        }
        
        # Find matching intent
        matched_intent = "conversational"  # Default
        confidence = 0.5
        
        for intent, patterns in intent_patterns.items():
            for pattern in patterns:
                if pattern in query:
                    matched_intent = intent
                    confidence = 0.8
                    break
            if confidence > 0.5:
                break
        
        # Use ML model if available
        if self.classifier_model and self.classifier_tokenizer:
            try:
                inputs = self.classifier_tokenizer(query, return_tensors="pt", truncation=True, padding=True)
                with torch.no_grad():
                    outputs = self.classifier_model(**inputs)
                    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
                    ml_confidence = float(torch.max(predictions))
                    
                    if ml_confidence > confidence:
                        confidence = ml_confidence
            except Exception as e:
                self.logger.warning("ML intent classification failed", error=str(e))
        
        return {
            "intent": matched_intent,
            "confidence": round(confidence, 3),
            "query": query,
            "classification_method": "ml" if confidence > 0.7 else "rule_based"
        }
    
    async def _answer_question(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Answer questions using knowledge base and QA model"""
        query = data.get("query", "")
        context = data.get("context", {})
        
        # Find relevant knowledge base entries
        relevant_knowledge = self._find_relevant_knowledge(query)
        
        # Use QA model if available
        if self.qa_model and self.qa_tokenizer and relevant_knowledge:
            try:
                # Prepare context for QA model
                context_text = " ".join([str(v) for v in relevant_knowledge.values()])
                
                inputs = self.qa_tokenizer(query, context_text, return_tensors="pt", truncation=True, padding=True)
                
                with torch.no_grad():
                    outputs = self.qa_model(**inputs)
                    start_scores = outputs.start_logits
                    end_scores = outputs.end_logits
                    
                    start_idx = torch.argmax(start_scores)
                    end_idx = torch.argmax(end_scores)
                    
                    answer_tokens = inputs["input_ids"][0][start_idx:end_idx+1]
                    answer = self.qa_tokenizer.decode(answer_tokens, skip_special_tokens=True)
                
                confidence = float(torch.max(torch.nn.functional.softmax(start_scores, dim=-1)))
                
            except Exception as e:
                self.logger.warning("QA model failed, using fallback", error=str(e))
                answer = self._fallback_answer(query, relevant_knowledge)
                confidence = 0.6
        else:
            answer = self._fallback_answer(query, relevant_knowledge)
            confidence = 0.6
        
        return {
            "answer": answer,
            "confidence": round(confidence, 3),
            "source": "knowledge_base",
            "relevant_sections": list(relevant_knowledge.keys()),
            "context_used": bool(context)
        }
    
    async def _generate_insights(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Generate insights based on query"""
        query = data.get("query", "")
        context = data.get("context", {})
        
        # Analyze query to determine insight type
        insight_type = self._determine_insight_type(query)
        
        # Generate insights based on type
        if insight_type == "system_overview":
            insights = self._generate_system_overview_insights()
        elif insight_type == "performance_analysis":
            insights = self._generate_performance_insights()
        elif insight_type == "threat_analysis":
            insights = self._generate_threat_insights()
        elif insight_type == "collaboration_insights":
            insights = self._generate_collaboration_insights()
        elif insight_type == "revenue_insights":
            insights = self._generate_revenue_insights()
        else:
            insights = self._generate_general_insights(query)
        
        return {
            "insight_type": insight_type,
            "insights": insights,
            "query": query,
            "generation_method": "ai_analysis",
            "confidence": 0.8
        }
    
    async def _search_knowledge(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Search knowledge base for relevant information"""
        query = data.get("query", "")
        
        # Find relevant knowledge base entries
        relevant_entries = self._find_relevant_knowledge(query)
        
        # Rank by relevance
        ranked_entries = self._rank_knowledge_entries(query, relevant_entries)
        
        return {
            "query": query,
            "results": ranked_entries,
            "total_results": len(ranked_entries),
            "search_method": "semantic_similarity"
        }
    
    async def _conversational_interface(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Handle conversational interactions"""
        query = data.get("query", "").lower()
        context = data.get("context", {})
        
        # Simple conversational responses
        responses = {
            "greeting": [
                "Hello! I'm the NLP Query Agent for the MSP Intelligence Mesh Network. How can I help you today?",
                "Hi there! I'm here to help you explore the MSP Intelligence Mesh Network. What would you like to know?",
                "Welcome! I can help you understand our AI agents, system capabilities, and provide insights. What's on your mind?"
            ],
            "thanks": [
                "You're welcome! Is there anything else I can help you with?",
                "Happy to help! Feel free to ask if you have more questions.",
                "My pleasure! Let me know if you need any other information."
            ],
            "help": [
                "I can help you with questions about our AI agents, system capabilities, insights, and more. Try asking me about threat intelligence, collaboration opportunities, or system performance.",
                "I'm here to assist with queries about the MSP Intelligence Mesh Network. You can ask about specific agents, request insights, or search for information.",
                "I can answer questions, generate insights, and help you explore the system. What would you like to know about?"
            ],
            "capabilities": [
                "I can answer questions, generate insights, search knowledge, and help you understand our AI agents and their capabilities.",
                "My capabilities include natural language query processing, knowledge base search, insight generation, and conversational assistance.",
                "I can help you explore the MSP Intelligence Mesh Network through natural language queries and provide detailed insights about our AI agents."
            ]
        }
        
        # Determine response type
        if any(word in query for word in ["hello", "hi", "hey", "good morning", "good afternoon"]):
            response_type = "greeting"
        elif any(word in query for word in ["thank", "thanks", "appreciate"]):
            response_type = "thanks"
        elif any(word in query for word in ["help", "assist", "support", "what can you do"]):
            response_type = "help"
        elif any(word in query for word in ["capabilities", "features", "what do you do"]):
            response_type = "capabilities"
        else:
            response_type = "general"
        
        # Generate response
        if response_type in responses:
            response = random.choice(responses[response_type])
        else:
            response = "I understand you're asking about something. Could you be more specific? I can help with questions about our AI agents, system insights, or general information about the MSP Intelligence Mesh Network."
        
        return {
            "response": response,
            "response_type": response_type,
            "suggestions": self._generate_suggestions(query),
            "context_aware": bool(context)
        }
    
    def _find_relevant_knowledge(self, query: str) -> Dict[str, Any]:
        """Find relevant knowledge base entries for a query"""
        query_lower = query.lower()
        relevant_entries = {}
        
        # Simple keyword matching
        for section, content in self.knowledge_base.items():
            relevance_score = 0
            
            # Check section name
            if any(word in section.lower() for word in query_lower.split()):
                relevance_score += 2
            
            # Check content
            if isinstance(content, dict):
                for key, value in content.items():
                    if isinstance(value, str):
                        if any(word in value.lower() for word in query_lower.split()):
                            relevance_score += 1
                    elif isinstance(value, list):
                        for item in value:
                            if isinstance(item, str) and any(word in item.lower() for word in query_lower.split()):
                                relevance_score += 1
            
            if relevance_score > 0:
                relevant_entries[section] = content
        
        return relevant_entries
    
    def _fallback_answer(self, query: str, relevant_knowledge: Dict[str, Any]) -> str:
        """Generate fallback answer when ML model is not available"""
        if not relevant_knowledge:
            return "I don't have specific information about that topic in my knowledge base. Could you try rephrasing your question or ask about our AI agents, system capabilities, or general MSP Intelligence Mesh Network features?"
        
        # Generate answer from relevant knowledge
        answer_parts = []
        
        for section, content in relevant_knowledge.items():
            if isinstance(content, dict) and "description" in content:
                answer_parts.append(f"{section.replace('_', ' ').title()}: {content['description']}")
            elif isinstance(content, str):
                answer_parts.append(f"{section.replace('_', ' ').title()}: {content}")
        
        if answer_parts:
            return " ".join(answer_parts[:2])  # Limit to first 2 parts
        else:
            return "I found some relevant information but couldn't generate a specific answer. Please try asking a more specific question."
    
    def _determine_insight_type(self, query: str) -> str:
        """Determine the type of insights requested"""
        query_lower = query.lower()
        
        if any(word in query_lower for word in ["overview", "summary", "status", "general"]):
            return "system_overview"
        elif any(word in query_lower for word in ["performance", "metrics", "health", "monitoring"]):
            return "performance_analysis"
        elif any(word in query_lower for word in ["threat", "security", "attack", "vulnerability"]):
            return "threat_analysis"
        elif any(word in query_lower for word in ["collaboration", "partnership", "matching", "opportunity"]):
            return "collaboration_insights"
        elif any(word in query_lower for word in ["revenue", "pricing", "forecast", "optimization"]):
            return "revenue_insights"
        else:
            return "general_insights"
    
    def _generate_system_overview_insights(self) -> List[Dict[str, Any]]:
        """Generate system overview insights"""
        return [
            {
                "category": "System Status",
                "insight": "MSP Intelligence Mesh Network is operating at 97% efficiency",
                "details": "All 8 AI agents are active and functioning optimally",
                "confidence": 0.95
            },
            {
                "category": "Network Health",
                "insight": "Network intelligence level is at 94%",
                "details": "1,247 MSPs are actively participating in the network",
                "confidence": 0.92
            },
            {
                "category": "Performance",
                "insight": "Average response time across all agents is 23ms",
                "details": "System is performing well within target parameters",
                "confidence": 0.98
            },
            {
                "category": "Security",
                "insight": "Threat detection accuracy is 94.2%",
                "details": "2,847 threats have been successfully blocked in the last 30 days",
                "confidence": 0.94
            }
        ]
    
    def _generate_performance_insights(self) -> List[Dict[str, Any]]:
        """Generate performance-related insights"""
        return [
            {
                "category": "Response Times",
                "insight": "All agents are responding within target timeframes",
                "details": "Threat Intelligence Agent: 15ms, Collaboration Agent: 28ms, Federated Learning Agent: 35ms",
                "confidence": 0.96
            },
            {
                "category": "Accuracy Metrics",
                "insight": "Model accuracy across agents is consistently high",
                "details": "Churn prediction: 94%, Threat detection: 94.2%, Revenue forecasting: 92%",
                "confidence": 0.93
            },
            {
                "category": "System Load",
                "insight": "System is operating at optimal capacity",
                "details": "CPU usage: 45%, Memory usage: 62%, Network utilization: 38%",
                "confidence": 0.89
            }
        ]
    
    def _generate_threat_insights(self) -> List[Dict[str, Any]]:
        """Generate threat-related insights"""
        return [
            {
                "category": "Threat Landscape",
                "insight": "Ransomware attacks are the most prevalent threat type",
                "details": "45% of detected threats are ransomware-related, with 23% being phishing attempts",
                "confidence": 0.91
            },
            {
                "category": "Detection Performance",
                "insight": "Threat detection response time has improved by 15% this month",
                "details": "Average detection time is now 23ms, down from 27ms last month",
                "confidence": 0.88
            },
            {
                "category": "Network Protection",
                "insight": "847 MSPs were automatically protected from recent threats",
                "details": "Network-wide threat response prevented $2.4M in potential damages",
                "confidence": 0.94
            }
        ]
    
    def _generate_collaboration_insights(self) -> List[Dict[str, Any]]:
        """Generate collaboration-related insights"""
        return [
            {
                "category": "Partnership Success",
                "insight": "Collaboration success rate is 78%",
                "details": "156 partnership opportunities were matched in the last month",
                "confidence": 0.87
            },
            {
                "category": "Revenue Generation",
                "insight": "$890K in revenue generated through collaborations",
                "details": "Average collaboration value is $5,700 per partnership",
                "confidence": 0.92
            },
            {
                "category": "Skill Matching",
                "insight": "AI-powered skill matching is 94% accurate",
                "details": "Complementary skill identification has improved partnership success",
                "confidence": 0.89
            }
        ]
    
    def _generate_revenue_insights(self) -> List[Dict[str, Any]]:
        """Generate revenue-related insights"""
        return [
            {
                "category": "Revenue Growth",
                "insight": "Average revenue increase per MSP is 35-40%",
                "details": "Revenue optimization strategies are showing consistent results",
                "confidence": 0.91
            },
            {
                "category": "Forecasting Accuracy",
                "insight": "Revenue forecasting accuracy is 92%",
                "details": "Prophet-based models are providing reliable predictions",
                "confidence": 0.88
            },
            {
                "category": "Upsell Opportunities",
                "insight": "67% upsell success rate for identified opportunities",
                "details": "AI-powered upsell recommendations are highly effective",
                "confidence": 0.85
            }
        ]
    
    def _generate_general_insights(self, query: str) -> List[Dict[str, Any]]:
        """Generate general insights based on query"""
        return [
            {
                "category": "Query Analysis",
                "insight": f"Your query about '{query}' relates to multiple system capabilities",
                "details": "I can provide more specific insights if you ask about particular agents or features",
                "confidence": 0.7
            },
            {
                "category": "System Capabilities",
                "insight": "The MSP Intelligence Mesh Network offers comprehensive AI-powered solutions",
                "details": "Our 8 specialized agents work together to provide threat intelligence, collaboration matching, and revenue optimization",
                "confidence": 0.95
            }
        ]
    
    def _rank_knowledge_entries(self, query: str, entries: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Rank knowledge base entries by relevance to query"""
        ranked_entries = []
        
        for section, content in entries.items():
            # Calculate relevance score
            relevance_score = self._calculate_relevance_score(query, section, content)
            
            ranked_entries.append({
                "section": section,
                "content": content,
                "relevance_score": relevance_score,
                "title": section.replace('_', ' ').title()
            })
        
        # Sort by relevance score
        ranked_entries.sort(key=lambda x: x["relevance_score"], reverse=True)
        
        return ranked_entries
    
    def _calculate_relevance_score(self, query: str, section: str, content: Any) -> float:
        """Calculate relevance score for knowledge base entry"""
        query_words = set(query.lower().split())
        section_words = set(section.lower().split())
        
        # Base score from section name match
        section_match = len(query_words.intersection(section_words)) / len(query_words)
        
        # Content match score
        content_score = 0
        if isinstance(content, dict):
            for key, value in content.items():
                if isinstance(value, str):
                    value_words = set(value.lower().split())
                    content_score += len(query_words.intersection(value_words)) / len(query_words)
                elif isinstance(value, list):
                    for item in value:
                        if isinstance(item, str):
                            item_words = set(item.lower().split())
                            content_score += len(query_words.intersection(item_words)) / len(query_words)
        
        return section_match + content_score * 0.5
    
    def _generate_suggestions(self, query: str) -> List[str]:
        """Generate helpful suggestions based on query"""
        suggestions = []
        
        query_lower = query.lower()
        
        if "threat" in query_lower or "security" in query_lower:
            suggestions.extend([
                "Ask about threat detection accuracy",
                "Request threat intelligence insights",
                "Query about security metrics"
            ])
        elif "collaboration" in query_lower or "partnership" in query_lower:
            suggestions.extend([
                "Ask about collaboration success rates",
                "Request partnership opportunities",
                "Query about skill matching"
            ])
        elif "revenue" in query_lower or "pricing" in query_lower:
            suggestions.extend([
                "Ask about revenue forecasting",
                "Request pricing optimization insights",
                "Query about market intelligence"
            ])
        else:
            suggestions.extend([
                "Ask about system overview",
                "Request performance insights",
                "Query about AI agent capabilities"
            ])
        
        return suggestions[:3]  # Limit to 3 suggestions
    
    def get_health_status(self) -> Dict[str, Any]:
        """Get agent health status"""
        return {
            "agent_id": self.agent_id,
            "status": "active" if self.model_loaded else "inactive",
            "model_loaded": self.model_loaded,
            "health_score": 0.93 if self.model_loaded else 0.0,
            "last_activity": datetime.utcnow().isoformat(),
            "metrics": {
                "total_requests": self.metrics.total_requests,
                "successful_requests": self.metrics.successful_requests,
                "average_response_time_ms": self.metrics.average_response_time_ms,
                "error_rate": self.metrics.error_rate
            }
        }

