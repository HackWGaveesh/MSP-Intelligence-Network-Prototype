version: "3.9"

services:
  model-download:
    image: python:3.11-slim
    working_dir: /app
    volumes:
      - ./:/app:rw
      - models_cache:/app/backend/models/pretrained
    command: >
      bash -lc "apt-get update && apt-get install -y git && \
      pip install -U pip && \
      pip install transformers sentence-transformers scikit-learn numpy torch --index-url https://download.pytorch.org/whl/cpu && \
      python backend/models/download_models.py"
    restart: "no"

  backend:
    image: python:3.11-slim
    working_dir: /app
    depends_on:
      model-download:
        condition: service_completed_successfully
    volumes:
      - ./:/app:rw
      - models_cache:/app/backend/models/pretrained
    environment:
      - TRANSFORMERS_CACHE=/app/backend/models/pretrained
      - HF_HOME=/app/backend/models/pretrained
    command: >
      bash -lc "apt-get update && apt-get install -y curl && \
      pip install -U pip && \
      pip install fastapi uvicorn[standard] transformers sentence-transformers scikit-learn numpy torch --index-url https://download.pytorch.org/whl/cpu && \
      python backend/api/main_simple.py"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 40s
    ports:
      - "8000:8000"
    restart: unless-stopped

  frontend:
    image: nginx:alpine
    depends_on:
      - backend
    volumes:
      - ./frontend:/usr/share/nginx/html:ro
    ports:
      - "8080:80"
    healthcheck:
      test: ["CMD-SHELL", "wget --spider -q http://localhost:80 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 20s
    restart: unless-stopped

volumes:
  models_cache:
    driver: local
